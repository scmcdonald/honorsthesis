---
title: "dataset_FINAL"
author: "Sarah McDonald"
date: "November 12, 2019"
output: html_document
---
# Set up
For the acquisition, four packages are needed: *gtools*, *dplyr*, *stringr*, and *stringi*. Additionally, we read in an csv file with the variables we want from each table.
```{r, warning= FALSE, message= FALSE}
library(gtools)
library(dplyr)
library(stringr) #to use str_trim
library(stringi)
library(tidyr)
library(sf)
library(ggplot2)
library(maptools)
library(plyr)
library(zoo)
library(rvest)
library(readxl)
variables <- read.csv("C:/Users/Sarah McDonald/Documents/honorsthesis/variables/ipeds_variables.csv")
```

We create a function called "Upper_Converter" that changes all strings to uppercase. Then, we also create a function call get "IPEDSData" that allows acquisition of the IPEDS data from the IPEDS website. When the data is read in, all variable names are made uppercase, and a year column is added to each dataset.
```{r, warning = FALSE, message = FALSE}

Upper_Converter <- function(strings){
  toupper(str_trim(iconv(strings, "ASCII", "UTF-8", sub="")))
}

getIPEDSData <- function(year, survey_file, capital_survey_file, extra = "", capital_extra = ""){
  dataset <- NULL
  temp <- tempfile()
  download.file(paste("https://nces.ed.gov/ipeds/datacenter/data/",  capital_survey_file, year, capital_extra, ".zip", sep = ""), temp)
  dataset <- read.csv(unz(temp, paste(survey_file, year, extra, ".csv", sep = "")))
  unlink(temp)
  names(dataset) <- toupper(names(dataset))
  dataset <- dataset %>% mutate_if(is.factor, Upper_Converter)
  dataset$YEAR <- year
  dataset
}
```

# Institutional Characteristics - Directory information

We use the loops below to acquire directory information from IPEDS for 1995 - 2017. Directory information is available from 1986. We use different loops below as naming conventions for the various tables change prior to 2002. We will need to come up with CBSA and Lat/Long for missing values in earlier years
```{r, warning = FALSE, message = FALSE}
# 2002 - 2017
survey_file <- "hd"
capital_survey_file <- "HD"
extra <- ""
capital_extra <- ""

for (year in 2002:2017){
  assign(paste(survey_file, year, extra, sep = ""), 
    getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

# 2000 - 2001
survey_file <- "fa"
capital_survey_file <- "FA"
extra <- "hd"
capital_extra <- "HD"

for (year in 2000:2001){
  assign(paste(survey_file, year, extra, sep = ""), 
    getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

# 1999
survey_file <- "ic"
capital_survey_file <- "IC"
extra <- "_hd"
capital_extra <- "_HD"

for (year in 99){
  assign(paste(survey_file, year, extra, sep = ""), 
    getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}
ic99_hd$YEAR <- "1999"

# 1998
survey_file <- "ic"
capital_survey_file <- "IC"
extra <- "hdac"
capital_extra <- "HDAC"

for (year in 98){
  assign(paste(survey_file, year, extra, sep = ""), 
    getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}
ic98hdac$YEAR <- "1998"

# 1997
survey_file <- "ic"
capital_survey_file <- "ic"
extra <- "_hdr"
capital_extra <- "_HDR"

for (year in 9798){
  assign(paste(survey_file, year, extra, sep = ""), 
    getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}
ic9798_hdr$YEAR <- "1997"

# 1995 - 1996
survey_file <- "ic"
capital_survey_file <- "ic"
extra <- "_a"
capital_extra <- "_A"

for (year in c(9596,9697)){
  assign(paste(survey_file, year, extra, sep = ""), 
    getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}
ic9596_a$YEAR <- "1995"
ic9697_a$YEAR <- "1996"

survey_file <- "ic"
capital_survey_file <- "ic"
extra <- "_a"
capital_extra <- "_A"

for (year in c(1992:1994)){
   assign(paste(survey_file, year, extra, sep = ""), 
    getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

ic1992_a$YEAR <- "1992"
ic1993_a$YEAR <- "1993"
ic1994_a$YEAR <- "1994"

survey_file <- "ic"
capital_survey_file <- "ic"
extra <- "_hdr"
capital_extra <- "_HDR"

for (year in c(1991)){
   assign(paste(survey_file, year, extra, sep = ""), 
    getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

ic1991_hdr$YEAR <- "1991"


survey_file <- "ic"
capital_survey_file <- "IC"
extra <- "hd"
capital_extra <- "HD"

for (year in c(90)){
   assign(paste(survey_file, year, extra, sep = ""), 
    getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

ic90hd$YEAR <- "1990"
```

We then use the following code to select our variables of interest from each directory information table and merge the tables for each year into one large table.
```{r, warning = FALSE, message=FALSE}
HD <- mget(ls(pattern = c("(hd\\d{4})|(ic\\d+(hd\\w?\\w?|_\\w+))|(fa.+)")))

levels(variables$Variable.Name) <- c(levels(variables$Variable.Name),"YEAR") 
variables[nrow(variables) + 1,] = list(Table= factor("HD"),Variable.Number= 9999, Variable.Name= factor("YEAR"))
HD_var <- variables[variables$Table == "HD", 3]

HD <- lapply(HD, function(x) x[(names(x)) %in% HD_var])
HD_df <- do.call("smartbind", HD)
```


# Fall Enrollment - Race/ethnicity, gender, attendance status, and level of student
We use the loops below to acquire the fall enrollment data (Race/Ethnicty/Gender) from IPEDS for 2000 - 2017. In 2008, the variable names changed from the old system to a new system, so I choose the new naming system. We changed the variable names in the tables prior to 2008 to the corresponding variable name that matches the new system. *I have code that can acquire 1980, 1986-1999 if needed.*

```{r, warning = FALSE, message = FALSE}
survey_file <- "ef"
capital_survey_file <- "EF"
extra <- "a"
capital_extra <- "A"

for (year in 2000:2017){
  assign(paste(survey_file, year, extra, sep = ""), 
         getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

#fix 2000
#2000 total men
colnames(ef2000a)[colnames(ef2000a)=="EFRACE15"] <- "EFTOTLM"
#2000 total women
colnames(ef2000a)[colnames(ef2000a)=="EFRACE16"] <- "EFTOTLW"
#total men and women
ef2000a$EFTOTLT <- ef2000a$EFTOTLM + ef2000a$EFTOTLW


#2000 total Hispanic men
colnames(ef2000a)[colnames(ef2000a)=="EFRACE09"] <- "EFHISPM"
colnames(ef2000a)[colnames(ef2000a)=="EFRACE10"] <- "EFHISPW"

#total hispanic men and women
ef2000a$EFHISPT <- ef2000a$EFHISPW + ef2000a$EFHISPM


#fix 2001
#2001 total men
colnames(ef2001a)[colnames(ef2001a)=="EFRACE15"] <- "EFTOTLM"
#2001 total women
colnames(ef2001a)[colnames(ef2001a)=="EFRACE16"] <- "EFTOTLW"
#total men and women
ef2001a$EFTOTLT <- ef2001a$EFTOTLM + ef2001a$EFTOTLW

#2001 total Hispanic 
colnames(ef2001a)[colnames(ef2001a)=="EFRACE09"] <- "EFHISPM"
colnames(ef2001a)[colnames(ef2001a)=="EFRACE10"] <- "EFHISPW"

#total hispanic men and women
ef2001a$EFHISPT <- ef2001a$EFHISPW + ef2001a$EFHISPM

#fix 2002
#grand total
colnames(ef2002a)[colnames(ef2002a)=="EFRACE24"] <- "EFTOTLT"
#total men
colnames(ef2002a)[colnames(ef2002a)=="EFRACE15"] <- "EFTOTLM"
# total hispanic men and women
colnames(ef2002a)[colnames(ef2002a)=="EFRACE21"] <- "EFHISPT"

#fix 2003
#grand total
colnames(ef2003a)[colnames(ef2003a)=="EFRACE24"] <- "EFTOTLT"
#total men
colnames(ef2003a)[colnames(ef2003a)=="EFRACE15"] <- "EFTOTLM"
# total hispanic men and women
colnames(ef2003a)[colnames(ef2003a)=="EFRACE21"] <- "EFHISPT"

#fix 2004
#grand total
colnames(ef2004a)[colnames(ef2004a)=="EFRACE24"] <- "EFTOTLT"
#total men
colnames(ef2004a)[colnames(ef2004a)=="EFRACE15"] <- "EFTOTLM"
# total hispanic men and women
colnames(ef2004a)[colnames(ef2004a)=="EFRACE21"] <- "EFHISPT"

#fix 2005
#grand total
colnames(ef2005a)[colnames(ef2005a)=="EFRACE24"] <- "EFTOTLT"
#total men
colnames(ef2005a)[colnames(ef2005a)=="EFRACE15"] <- "EFTOTLM"
# total hispanic men and women
colnames(ef2005a)[colnames(ef2005a)=="EFRACE21"] <- "EFHISPT"

#fix 2006
#grand total
colnames(ef2006a)[colnames(ef2006a)=="EFRACE24"] <- "EFTOTLT"
#total men
colnames(ef2006a)[colnames(ef2006a)=="EFRACE15"] <- "EFTOTLM"
# total hispanic men and women
colnames(ef2006a)[colnames(ef2006a)=="EFRACE21"] <- "EFHISPT"

#fix 2007
#grand total
colnames(ef2007a)[colnames(ef2007a)=="EFRACE24"] <- "EFTOTLT"
#total men
colnames(ef2007a)[colnames(ef2007a)=="EFRACE15"] <- "EFTOTLM"
# total hispanic men and women
colnames(ef2007a)[colnames(ef2007a)=="EFRACE21"] <- "EFHISPT"


survey_file <- "ef"
capital_survey_file <- "EF"
extra <- "_anr"
capital_extra <- "_ANR"

for (year in 95:99){
  assign(paste(survey_file, year, extra, sep = ""), 
         getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

for (year in 1994){ 
 assign(paste(survey_file, year, extra, sep = ""), 
         getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

ef1994_anr$year <- "1994"
ef95_anr$year <- "1995"
ef96_anr$year <- "1996"
ef97_anr$year <- "1997"
ef98_anr$year <- "1998"
ef99_anr$year <- "1999"

colnames(ef99_anr)[colnames(ef99_anr)=="EFRACE24"] <- "EFTOTLT"
colnames(ef99_anr)[colnames(ef99_anr)=="EFRACE15"] <- "EFTOTLM"
colnames(ef99_anr)[colnames(ef99_anr)=="EFRACE21"] <- "EFHISPT"

colnames(ef99_anr)[colnames(ef99_anr)=="EFRACE24"] <- "EFTOTLT"
colnames(ef99_anr)[colnames(ef99_anr)=="EFRACE15"] <- "EFTOTLM"
colnames(ef99_anr)[colnames(ef99_anr)=="EFRACE21"] <- "EFHISPT"

colnames(ef98_anr)[colnames(ef98_anr)=="EFRACE15"] <- "EFTOTLM"
colnames(ef98_anr)[colnames(ef98_anr)=="EFRACE16"] <- "EFTOTLW"
ef98_anr$EFTOTLT <- ef98_anr$EFTOTLM + ef98_anr$EFTOTLW
colnames(ef98_anr)[colnames(ef98_anr)=="EFRACE09"] <- "EFHISPM"
colnames(ef98_anr)[colnames(ef98_anr)=="EFRACE10"] <- "EFHISPW"
ef98_anr$EFHISPT <- ef98_anr$EFHISPW + ef98_anr$EFHISPM

colnames(ef97_anr)[colnames(ef97_anr)=="EFRACE15"] <- "EFTOTLM"
colnames(ef97_anr)[colnames(ef97_anr)=="EFRACE16"] <- "EFTOTLW"
ef97_anr$EFTOTLT <- ef97_anr$EFTOTLM + ef97_anr$EFTOTLW
colnames(ef97_anr)[colnames(ef97_anr)=="EFRACE09"] <- "EFHISPM"
colnames(ef97_anr)[colnames(ef97_anr)=="EFRACE10"] <- "EFHISPW"
ef97_anr$EFHISPT <- ef97_anr$EFHISPW + ef97_anr$EFHISPM

colnames(ef96_anr)[colnames(ef96_anr)=="EFRACE15"] <- "EFTOTLM"
colnames(ef96_anr)[colnames(ef96_anr)=="EFRACE16"] <- "EFTOTLW"
ef96_anr$EFTOTLT <- ef96_anr$EFTOTLM + ef96_anr$EFTOTLW
colnames(ef96_anr)[colnames(ef96_anr)=="EFRACE09"] <- "EFHISPM"
colnames(ef96_anr)[colnames(ef96_anr)=="EFRACE10"] <- "EFHISPW"
ef96_anr$EFHISPT <- ef96_anr$EFHISPW + ef96_anr$EFHISPM

colnames(ef95_anr)[colnames(ef95_anr)=="EFRACE15"] <- "EFTOTLM"
colnames(ef95_anr)[colnames(ef95_anr)=="EFRACE16"] <- "EFTOTLW"
ef95_anr$EFTOTLT <- ef95_anr$EFTOTLM + ef95_anr$EFTOTLW
colnames(ef95_anr)[colnames(ef95_anr)=="EFRACE09"] <- "EFHISPM"
colnames(ef95_anr)[colnames(ef95_anr)=="EFRACE10"] <- "EFHISPW"
ef95_anr$EFHISPT <- ef95_anr$EFHISPW + ef95_anr$EFHISPM

colnames(ef1994_anr)[colnames(ef1994_anr)=="EFRACE15"] <- "EFTOTLM"
colnames(ef1994_anr)[colnames(ef1994_anr)=="EFRACE16"] <- "EFTOTLW"
ef1994_anr$EFTOTLT <- ef1994_anr$EFTOTLM + ef1994_anr$EFTOTLW
colnames(ef1994_anr)[colnames(ef1994_anr)=="EFRACE09"] <- "EFHISPM"
colnames(ef1994_anr)[colnames(ef1994_anr)=="EFRACE10"] <- "EFHISPW"
ef1994_anr$EFHISPT <- ef1994_anr$EFHISPW + ef1994_anr$EFHISPM

survey_file <- "ef"
capital_survey_file <- "EF"
extra <- "_a"
capital_extra <- "_A"

for (year in 1991:1993){try(
    assign(paste(survey_file, year, extra, sep = ""), 
           getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra)))
}

#this gets 1990
for (year in 90){
    assign(paste(survey_file, year, extra, sep = ""), 
           getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

ef90_a$year <- "1990"
ef1991_a$year <- "1991"
ef1992_a$year <- "1992"
ef1993_a$year <- "1993"

colnames(ef1993_a)[colnames(ef1993_a)=="EFRACE15"] <- "EFTOTLM"
colnames(ef1993_a)[colnames(ef1993_a)=="EFRACE16"] <- "EFTOTLW"
ef1993_a$EFTOTLT <- ef1993_a$EFTOTLM + ef1993_a$EFTOTLW
colnames(ef1993_a)[colnames(ef1993_a)=="EFRACE09"] <- "EFHISPM"
colnames(ef1993_a)[colnames(ef1993_a)=="EFRACE10"] <- "EFHISPW"
ef1993_a$EFHISPT <- ef1993_a$EFHISPW + ef1993_a$EFHISPM

colnames(ef1992_a)[colnames(ef1992_a)=="EFRACE15"] <- "EFTOTLM"
colnames(ef1992_a)[colnames(ef1992_a)=="EFRACE16"] <- "EFTOTLW"
ef1992_a$EFTOTLT <- ef1992_a$EFTOTLM + ef1992_a$EFTOTLW
colnames(ef1992_a)[colnames(ef1992_a)=="EFRACE09"] <- "EFHISPM"
colnames(ef1992_a)[colnames(ef1992_a)=="EFRACE10"] <- "EFHISPW"
ef1992_a$EFHISPT <- ef1992_a$EFHISPW + ef1992_a$EFHISPM

colnames(ef1991_a)[colnames(ef1991_a)=="EFRACE15"] <- "EFTOTLM"
colnames(ef1991_a)[colnames(ef1991_a)=="EFRACE16"] <- "EFTOTLW"
ef1991_a$EFTOTLT <- ef1991_a$EFTOTLM + ef1991_a$EFTOTLW
colnames(ef1991_a)[colnames(ef1991_a)=="EFRACE09"] <- "EFHISPM"
colnames(ef1991_a)[colnames(ef1991_a)=="EFRACE10"] <- "EFHISPW"
ef1991_a$EFHISPT <- ef1991_a$EFHISPW + ef1991_a$EFHISPM

colnames(ef90_a)[colnames(ef90_a)=="EFRACE15"] <- "EFTOTLM"
colnames(ef90_a)[colnames(ef90_a)=="EFRACE16"] <- "EFTOTLW"
ef90_a$EFTOTLT <- ef90_a$EFTOTLM + ef90_a$EFTOTLW
colnames(ef90_a)[colnames(ef90_a)=="EFRACE09"] <- "EFHISPM"
colnames(ef90_a)[colnames(ef90_a)=="EFRACE10"] <- "EFHISPW"
ef90_a$EFHISPT <- ef90_a$EFHISPW + ef90_a$EFHISPM

```



We then use the following code to select our variables of interest from each fall enrollment(race/ethnicity/gender) table and merge the tables for each year into one large table. 

```{r, warning = FALSE, message = FALSE}
#2000-2017 (file is too big)
EFA <- mget(ls(pattern = c("ef\\d*(a|_)a?\\w?\\w?")))

levels(variables$Variable.Name) <- c(levels(variables$Variable.Name),"YEAR") 
variables[nrow(variables) + 1,] = list(Table= factor("EF_A"),Variable.Number= 9999, Variable.Name= factor("YEAR"))
EFA_var <- variables[variables$Table == "EF_A", 3]

# Merge and and only use the columns in our variable list

EFA <- lapply(EFA, function(x) x[(names(x)) %in% EFA_var])
EFA_df <- do.call("smartbind", EFA)



EFA_df$LINE <- as.character(EFA_df$LINE)

EFA_df <- EFA_df %>% filter(LINE == "8" | LINE == "22"| LINE == "29")

EFA_df$LINE[EFA_df$LINE == "8"] <- "Undergraduates"
EFA_df$LINE[EFA_df$LINE == "22"] <- "Undergraduates"
EFA_df$LINE[EFA_df$LINE == "29"] <- "Total"

detach(package:plyr)    
library(dplyr)

EFA_df <- EFA_df %>% group_by(UNITID, LINE, YEAR) %>% summarize(EFTOTLM = sum(EFTOTLM, na.rm=TRUE), EFTOTLT = sum(EFTOTLT, na.rm = TRUE), EFHISPT = sum(EFHISPT, na.rm = TRUE))


EFA_df$YEAR <- ifelse(nchar(EFA_df$YEAR) != 4, gsub(" ", "", paste("19", EFA_df$YEAR), fixed = TRUE), EFA_df$YEAR)

EFA_df <- EFA_df %>% gather(4:6, key = "Type", value = "Count")
EFA_df <- EFA_df %>% spread(key = LINE, value = Count)
EFA_df$Graduate <- EFA_df$Total - EFA_df$Undergraduates
EFA_df <- EFA_df %>% gather(Total, Undergraduates, Graduate, key = "LINE", value = "Count")
EFA_df <- EFA_df %>% spread(Type, Count)

```




# Institutional Characteristics - Educational offerings, organization, services and athletic associations

The code below acquires the institutional characteristics variables of interest, specifically religious affiliation for 2000-2017. *The data is available from 1980 if needed - I can easily write code to include earlier years if needed*.
```{r, warning = FALSE, message = FALSE}
survey_file <- "ic"
capital_survey_file <- "IC"
extra <- ""
capital_extra <- ""

#2000-2012. Available from 1980
for (year in 2000:2017){
    assign(paste(survey_file, year, extra, sep = ""), 
           getIPEDSData(year, survey_file, capital_survey_file, extra, capital_extra))
}

```

Then, we made one big data frame.
```{r, warning = FALSE, message = FALSE}
IC <- mget(ls(pattern = "^ic\\d{4}$"))

levels(variables$Variable.Name) <- c(levels(variables$Variable.Name),"YEAR") 
variables[nrow(variables) + 1,] = list(Table= factor("IC"),Variable.Number= 9999, Variable.Name= factor("YEAR"))
IC_var <- variables[variables$Table == "IC", 3]

# Merge and and only use the columns in our variable list
IC <- lapply(IC, function(x) x[(names(x)) %in% IC_var])
IC_df <- do.call("smartbind", IC)
```



```{r, warning = FALSE, message = FALSE}
data <- merge(IC_df, HD_df, by = c("UNITID", "YEAR"), all.x = TRUE, all.y = TRUE)
data <- merge(data, EFA_df, by.x = c("UNITID", "YEAR"), by.y = c("UNITID", "YEAR"), all.x = TRUE, all.y = TRUE)
#write.csv(data, "C:/Users/Sarah McDonald/Documents/honorsthesis/raw_data/original_ipeds.csv", row.names = FALSE)

data <- read.csv("C:/Users/Sarah McDonald/Documents/honorsthesis/raw_data/original_ipeds.csv")

```

#####interpolate institution names
First, I was going to interpolate missing institution names 

I found that only INSTNMs were blank in 1991 and 1992. None of the UNITIDs can be found in the directories for 1991 and 1992. Then I went back to our education data package from Urban institute to check this, and found the same results.

I also check directories found on Google Books and could find the the UNITIDs
https://play.google.com/books/reader?id=OJ73D2-uMnQC&hl=en&pg=GBS.PR1
https://play.google.com/books/reader?id=UI6xzGnaLjwC&hl=en&pg=GBS.PP1

THIS NEEDS TO BE CHECKED BECAUSE 6993 OBSERVATIONS IS A LOT.

We remove these observations.
```{r}
#library(educationdata)
#naINSTNM <- data %>% select(INSTNM, UNITID, YEAR) %>% filter(is.na(INSTNM) == TRUE)
#naINSTNM %>% filter(naINSTNM$UNITID %in% ic1991_hdr$UNITID)
#naINSTNM %>% filter(naINSTNM$UNITID %in% ic1992_a$UNITID)


#test_na_INSTNM <- get_education_data(level = "college-university",
                    #       source = "ipeds",
                     #      topic = "fall-enrollment",
                      #     filters = list(year = 1991, level_of_study = "undergraduate", race =3, sex = 1),
                       #    by = list("race", "sex"))



#test2_na_INSTNM <- get_education_data(level = "college-university",
                  #         source = "ipeds",
                   #        topic = "directory",
                    #       filters = list(year = 1991, unitid = 267115))

data <- data %>% filter(is.na(INSTNM) == FALSE)
```

######Geography Manipulation


Since we find that state are complete after removing our missing 1991 and 1992 schools, we remove the following: American Samoa,Federated States of Micronesia, Guam, Marshall Islands, Northern Marianas, Palau,Puerto Rico, and Virgin Islands as they are outside the scope of our analyses.



```{r, warnings = FALSE, message = FALSE}

data <- data %>% filter(STABBR != "AS" & STABBR != "FM" & STABBR != "GU" & STABBR != "MH" & STABBR != "MP" & STABBR != "PW" & STABBR != "PR" & STABBR != "VI")


```

# we tried using shape files for school-county-dioceses, but this was inaccurate
# now we use Zip code to county from HUD 4th Quarter 2017
# https://www.huduser.gov/portal/datasets/usps_crosswalk.html


We make the call to only match 2017 zip codes, as zip codes are not stable over time... we will assume that institutions do not change county over time

https://anthonylouisdagostino.com/a-better-zip5-county-crosswalk/
https://www.zip-codes.com/zip-code/27695/zip-code-27695.asp
https://nces.ed.gov/globallocator/index.asp?search=1&State=&city=&zipcode=&miles=&itemname=pardee&sortby=name&School=1&PrivSchool=1&College=1&Status=Search+Finished&Records=104&CS=A56C2DD
```{r, warnings = FALSE, message = FALSE}

#ZIP MISSING/UNUSABLE COUNTIESE
#LONG MISSING?UNUSABLE VALUES

#remove where all enrollment counts equal NA
data <-data[rowSums(is.na(data[c("EFHISPT", "EFTOTLM", "EFTOTLT")])) != 3, ]
data$ZIP <- as.character(data$ZIP)
#detach(package:plyr)    
library(dplyr)
data %>% select(ZIP) %>% group_by(nchar(ZIP)) %>% summarize(count = n())



#fix nchar = 1 value
#choose teh 1992 value for 1991 typo
data[data$INSTNM== "LA JAMES COLLEGE OF HAIR STYLING" & data$ZIP == "0", "ZIP"] <- "61244"



#check max number of characters for zip code HUD it is 5


data$ZIP <- ifelse(nchar(data$ZIP) == 4,  paste0("0", data$ZIP), data$ZIP)


data$ZIP <- ifelse(nchar(data$ZIP)==10, substr(data$ZIP, 1, 5), data$ZIP)


data$ZIP <- ifelse(nchar(data$ZIP) == 8,  paste0("0", data$ZIP), data$ZIP)

data$ZIP <- ifelse(nchar(data$ZIP)==9, substr(data$ZIP, 1, 5), data$ZIP)

data[data$UNITID== "234906" & is.na(data$ZIP) == TRUE, "ZIP"] <- "98312"

library(haven)

zipcode <- read_dta("C:/Users/Sarah McDonald/Documents/honorsthesis/raw_data/ZIP5_County_Crosswalk.dta")
zipcode$zip5<- as.character(zipcode$zip5)
zipcode$state_fips <- as.character(zipcode$state_fips)
zipcode$county_fips <- as.character(zipcode$county_fips)

zipcode$zip5 <- ifelse(nchar(zipcode$zip5)==3,  paste0("00", zipcode$zip5), zipcode$zip5)
zipcode$zip5 <- ifelse(nchar(zipcode$zip5)==4,  paste0("0", zipcode$zip5), zipcode$zip5)

zipcode$county <- ifelse(nchar(zipcode$county)==4,  paste0("0", zipcode$county), zipcode$county)




zip.2017 <- data %>% filter(YEAR == 2017 & LINE == "Total")


#checked school website SIT, VT
zip.2017[zip.2017$ZIP == "05302" & zip.2017$UNITID == 231068, "ZIP"] <- "05301"

#LENOIR COMMUNITY COLLEGE, NC checked NC CC website
zip.2017[zip.2017$ZIP == "28502" & zip.2017$UNITID == 198817, "ZIP"] <- "28504"

#PardEE Rand is in  LA County
zip.2017[zip.2017$ZIP == "90407" & zip.2017$UNITID == 121628, "ZIP"] <- "90401"

#Texas A&M , checked webiste
zip.2017[zip.2017$ZIP == "75429" & zip.2017$UNITID == 224554, "ZIP"] <- "75428"

#southern methodist checked webstie
zip.2017[zip.2017$ZIP == "75275" & zip.2017$UNITID == 228246, "ZIP"] <- "75205"

#U Cinncinati website

zip.2017[zip.2017$ZIP == "45221" & zip.2017$UNITID == 201885, "ZIP"] <- "45220"

#SUMMIT SALON ACADEMY-PERRYSBURG checked website

zip.2017[zip.2017$ZIP == "45551" & zip.2017$UNITID == 457916, "ZIP"] <- "43551"

#NICHOLLS STATE UNIVERSITY
zip.2017[zip.2017$ZIP == "70310" & zip.2017$UNITID == 159966, "ZIP"] <- "70301"

#SOUTHERN UNIVERSITY LAW CENTER website to google maps


zip.2017[zip.2017$ZIP == "70813" & zip.2017$UNITID == 440916, "ZIP"] <- "70807"
#SOUTHERN UNIVERSITY AND A & M COLLEGE webstie to google maps
zip.2017[zip.2017$ZIP == "70813" & zip.2017$UNITID == 160621, "ZIP"] <- "70807"

#UNIVERSITY OF ARKANSAS AT MONTICELLO website to google maps

zip.2017[zip.2017$ZIP == "71656" & zip.2017$UNITID == 106485, "ZIP"] <- "71655"


zip.2017 <- merge(zip.2017[, c("ZIP", "UNITID") ], zipcode[ ,c("zip5", "county")], by.x= "ZIP", by.y = "zip5", all.x = TRUE)

#fix non mergers
#NCSU, RALeigh NC is in Wake County
zip.2017[zip.2017$ZIP == "27695" & zip.2017$UNITID == 199193, "county"] <- "37183"

#UA isin Tuscaloosa County

zip.2017[zip.2017$ZIP == "35487" & zip.2017$UNITID == 100751, "county"] <- "01125"

#THE UNIVERSITY OF TENNESSEE-HEALTH SCIENCE CENTER shelby county
zip.2017[zip.2017$ZIP == "38163" & zip.2017$UNITID == 487010, "county"] <- "47157"

#UNIVERSITY OF ARKANSAS COMMUNITY COLLEGE-BATESVILLE is in Independence county
#
zip.2017[zip.2017$ZIP == "72503" & zip.2017$UNITID == 106999, "county"] <- "05063"

#LINCOLN LAND COMMUNITY COLLEGE is in Sangamon

zip.2017[zip.2017$ZIP == "62794" & zip.2017$UNITID == 146685, "county"] <- "17167"


data <- merge(data, zip.2017[, c("UNITID", "county")], by = "UNITID", all.x = TRUE )

county.na <- data %>% filter(is.na(county)==TRUE)






#Dioceses Shapefiles
#KML <- getKMLcoordinates(kmlfile = unzip(zipfile = "C:/Users/Sarah McDonald/Documents/honorsthesis/raw_data/US_Dioceses.kmz", exdir = "~/honorsthesis/KML"), ignoreAltitude = TRUE)
#cath_geo <- st_read("C:/Users/Sarah McDonald/Documents/honorsthesis/KML/doc.kml")

#Select coordinates for Universities in 2017
#coords_17 <- data %>% filter(YEAR == 2017 & LINE == "Total") %>% select(UNITID, LONGITUD, LATITUDE)
#coords_17$LONGITUD <- as.numeric(as.character(as.factor(coords_17$LONGITUD)))
#coords_17$LATITUDE <- as.numeric(as.character(as.factor(coords_17$LATITUDE)))
#coords_17 = st_as_sf(coords_17, coords = c("LONGITUD", "LATITUDE"), crs = st_crs(cath_geo))


#counties
#counties <- st_read("C:/Users/Sarah McDonald/Documents/honorsthesis/raw_data/census_2017_shapefiles/tl_2017_us_county.shp")
#counties = st_transform(counties, st_crs(cath_geo))
#remove islands
#counties <- counties %>% filter(as.numeric(as.character(as.factor(GEOID))) <  60000)


#inst_county <- st_join(coords_17, counties)

#inst_county %>%filter((is.na(GEOID) == TRUE))

#check values that did not match
##376695 Guam
#243647 Marshall islands
#243638 COLLEGE OF MICRONESIA

#inst_county <- inst_county %>%filter((is.na(GEOID) == FALSE))
#inst_county <- inst_county[, c(1, 5)]
#inst_county$GEOID <- as.character(as.factor(inst_county$GEOID))

#head(cath_geo$Description)
#cath_geo$Description <- str_extract(cath_geo$Description, 'Diocese(.*)SUM_SUM_POP2010')
#cath_geo$Description <- lapply(cath_geo$Description, function(x) gsub(c("(Diocese)?<.?t(d|r)>(SUM_SUM_POP2010)?"), "", x))


#cath_geo$Description <- trimws(cath_geo$Description)
#colnames(cath_geo)[colnames(cath_geo) == "Description"] <- "Dioceses"

#dioceses <- cath_geo$Dioceses
#write.csv(dioceses, "dioceses_from_geo.csv")

#cent_count <- st_centroid(counties)
#count_dioceses <- st_join(cent_count, cath_geo, all = TRUE)

#count_dioceses <- count_dioceses %>% select(GEOID, NAME, Name, Dioceses, ALAND)
#count_dioceses<-st_set_geometry(count_dioceses, NULL)

#inst_county<-st_set_geometry(inst_county, NULL)
#inst_county_dioceses <- merge(inst_county, count_dioceses, by = "GEOID", all.x = TRUE)

#data <- merge(data, inst_county_dioceses[, c(1:2, 5:6)], by = "UNITID", all.x = TRUE)
```



```{r}
# Sector = 3, 6, 9 shows FOR PROFIT, CNTLAFFI shows FOR PROFIT
data %>% filter((SECTOR== 9 | SECTOR == 6|SECTOR == 3) & CNTLAFFI != 2)
# only issues are the ones that say "3"... "-1" means NA


#Sector = 1,4,7 should got to 1 PUBLIC
test<-data %>% filter((SECTOR== 7 | SECTOR == 4|SECTOR == 1) & CNTLAFFI != 1) # not an issue because CNTAFFIL ==1

#Sector = 2,5,8 = CNTAFFIL = 3 or 4
test<-data %>% filter((SECTOR== 8 | SECTOR == 5|SECTOR == 2) & (CNTLAFFI != 3 & CNTLAFFI !=4))

# SECTOR IS ALWAYS PRESENT
data %>% filter(is.na(SECTOR)==TRUE)

#public
data[data$SECTOR == 1 , "CNTLAFFI"] <- 1
data[data$SECTOR == 4 , "CNTLAFFI"] <- 1
data[data$SECTOR == 7 , "CNTLAFFI"] <- 1

#for-profit
data[data$SECTOR == 3 , "CNTLAFFI"] <- 2
data[data$SECTOR == 6 , "CNTLAFFI"] <- 2
data[data$SECTOR == 9 , "CNTLAFFI"] <- 2

test <-data %>% select(SECTOR, CNTLAFFI) %>% group_by(CNTLAFFI, SECTOR) %>% summarize(n = n())

test2 <- data %>% filter(is.na(CNTLAFFI)==TRUE)

```






```{r, warning = FALSE, message = FALSE}
var <- read.csv("C:/Users/Sarah McDonald/Documents/honorsthesis/variables/variables2.csv")
sector <- var %>% filter(varname == "SECTOR")
data <- merge(data, sector[, c("codevalue","valuelabel")], by.x = "SECTOR", by.y = "codevalue", all.x = TRUE)
data <- subset(data,select=-c(SECTOR))
colnames(data)[colnames(data) == "valuelabel"] <- "SECTOR"
```


```{r, warning=FALSE, message=FALSE}
pubprivate <- var %>% filter(varname == "CNTLAFFI")

data <- merge(data, pubprivate[, c("codevalue", "valuelabel")], by.x = "CNTLAFFI", by.y = "codevalue", all.x = TRUE)
data <- subset(data,select=-c(CNTLAFFI))
colnames(data)[colnames(data) == "valuelabel"] <- "PUBPRIVATE"
```

```{r, warning = FALSE, message = FALSE}
relaff <- var %>% filter(varname == "RELAFFIL")

data <- merge(data, relaff[, c("codevalue", "valuelabel")], by.x = "RELAFFIL", by.y = "codevalue", all.x = TRUE)
data <- subset(data,select=-c(RELAFFIL))
colnames(data)[colnames(data) == "valuelabel"] <- "RELAFFIL"
```

```{r, warning = FALSE, message = FALSE}
deggrant <- var %>% filter(varname == "DEGGRANT")
data <- merge(data, deggrant[, c("codevalue", "valuelabel")], by.x = "DEGGRANT", by.y = "codevalue", all.x = TRUE)
data <- subset(data,select=-c(DEGGRANT))
colnames(data)[colnames(data) == "valuelabel"] <- "DEGGRANT"
```


Assumption: doctoral I and research I used to be separate. Listed together in 2017 as Doctoral/Research - extensive

```{r, warning = FALSE, message = FALSE}
carnegie <- var %>% filter(varname == "CARNEGIE")
data <- merge(data, carnegie[, c("codevalue", "valuelabel")], by.x = "CARNEGIE", by.y = "codevalue", all.x = TRUE)
data <- subset(data,select=-c(CARNEGIE))
colnames(data)[colnames(data) == "valuelabel"] <- "CARNEGIE"
```
Next, we tried to use the following interpolation script using na.locf. However, this cause issues with numbers not matching up between sector and cntlaffil
###MASSIVE INTERPOLATION SCRIPT
```{r, warning = FALSE, message = FALSE}
#library(plyr)
#data[levels(data$CARNEGIE)=="{Item not available}"] <- NA
#data$CARNEGIE <- revalue(data$CARNEGIE, c("{Item not available}"=NA))
#data$DEGGRANT <- revalue(data$DEGGRANT, c("{Not available}"=NA))


#School_location <- data[,c("UNITID", "INSTNM", "LONGITUD", "LATITUDE", "YEAR")]
#School_locations <- unique(School_location[order(School_location$UNITID, 
                   #                              School_location$YEAR, 
                    #                             decreasing = TRUE),])

# Your latitude and longitude variables are factors--NO! They should be numeric
#School_locations$LONGITUD <- as.numeric(paste(School_locations$LONGITUD))
#School_locations$LATITUDE <- as.numeric(paste(School_locations$LATITUDE))

# Last obs. carried forward—closest year info will fall down (e.g.: 2009, to 2008, to 2007….)
#School_locations$UNITID <- na.locf(School_locations$UNITID)
#School_locations$INSTNM <- na.locf(School_locations$INSTNM)
#School_locations$LONGITUD <- na.locf(School_locations$LONGITUD)
#School_locations$LATITUDE <- na.locf(School_locations$LATITUDE)

#School_locations <- unique(School_locations)

# Get the difference in Lats and longs and units to see which schools have 
# different information over the years--aka problem schools
# These may not be problems, but it will be good to keep this list if 
# we notice outliers later on, these may be it! These are schools that moved 
# from year to year and thus could have different counties.
#School_locations$ID_Diff <- c(0,diff(round(as.numeric(School_locations$UNITID)), differences = 1))
#School_locations$Lat_Diff <- c(0,diff(round(as.numeric(School_locations$LATITUDE)), differences = 1))
#School_locations$Long_Diff <- c(0,diff(round(as.numeric(School_locations$LONGITUD)), differences = 1))
#Problem_IDS <- School_locations[School_locations$ID_Diff == 0 & 
                               #   (School_locations$Long_Diff != 0 &
                               #      School_locations$Lat_Diff != 0),]$UNITID
#Problem_Schools <- School_locations[School_locations$UNITID %in% Problem_IDS,]
#Problem_Schools_in_IPEDS <- data[data$UNITID %in% Problem_IDS,]
#School_locations_Final <- School_locations[,-6:-8]

# I believe you could choose to overwrite the existing INSTNM, LAT and LONG
# with your new dataset, but didn't here in case you have an issue with the creation
#data <- merge(data, School_locations_Final, by = c("UNITID", "YEAR"), all.x = TRUE)

#
#data <- subset(data,select=-c(INSTNM.x, LONGITUD.x, LATITUDE.x))

#colnames(data)[colnames(data) == "INSTNM.y"] <- "INSTNM"
#colnames(data)[colnames(data) == "LONGITUD.y"] <- "LONGITUD"
#colnames(data)[colnames(data) == "LATITUDE.y"] <- "LATITUDE"

##############other interpolations

#School_others <- data[,c("UNITID", "SECTOR", "PUBPRIVATE", "RELAFFIL", "DEGGRANT", "YEAR", "CARNEGIE")]
#School_others <- unique(School_others[order(School_others$UNITID, 
                                       #   School_others$YEAR, 
                                        #         decreasing = TRUE),])


# Last obs. carried forward—closest year info will fall down (e.g.: 2009, to 2008, to 2007….)
# added na.rm = FALSE because NAs in 2017 (leading NAs) cause and error
#School_others$PUBPRIVATE <- na.locf(School_others$PUBPRIVATE, na.rm = FALSE)
#School_others$SECTOR <- na.locf(School_others$SECTOR)
#School_others$RELAFFIL <- na.locf(School_others$RELAFFIL, na.rm = FALSE)
#School_others$DEGGRANT <- na.locf(School_others$DEGGRANT, na.rm = FALSE)
#School_others$CARNEGIE <- na.locf(School_others$CARNEGIE, na.rm = FALSE)

#School_others <- unique(School_others)

# Get the difference in Lats and longs and units to see which schools have 
# different information over the years--aka problem schools
# These may not be problems, but it will be good to keep this list if 
# we notice outliers later on, these may be it! These are schools that moved 
# from year to year and thus could have different counties.
#School_others$PUBPRIVATE_Diff <- c(0,diff(round(as.numeric(School_others$PUBPRIVATE)), differences = 1))
#School_others$SECTOR_Diff <- c(0,diff(round(as.numeric(School_others$SECTOR)), differences = 1))
#School_others$RELAFFIL_Diff <- c(0,diff(round(as.numeric(School_others$RELAFFIL)), differences = 1))
#School_others$DEGGRANT_Diff <- c(0,diff(round(as.numeric(School_others$DEGGRANT)), differences = 1))
#School_others$CARNEGIE_Diff <- c(0,diff(round(as.numeric(School_others$CARNEGIE)), differences = 1))

#Problem_IDS2 <- School_others[(School_others$PUBPRIVATE_Diff != 0 & 
            #                         School_others$SECTOR_Diff != 0 &
             #                        School_others$RELAFFIL_Diff != 0 &
              #                       School_others$DEGGRANT_Diff != 0 &
               #                    School_others$CARNEGIE_Diff != 0 ),]$UNITID

#Problem_Schools2 <- School_others[School_others$UNITID %in% Problem_IDS2,]
#Problem_Schools_in_IPEDS2 <- data[data$UNITID %in% Problem_IDS2,]
#School_others_Final <- School_others[,-8:-12]

# I believe you could choose to overwrite the existing INSTNM, LAT and LONG
# with your new dataset, but didn't here in case you have an issue with the creation
#data <- merge(data, School_others_Final, by = c("UNITID", "YEAR"), all.x = TRUE)

#data <- subset(data,select=-c(SECTOR.x, PUBPRIVATE.x, RELAFFIL.x, DEGGRANT.x, CARNEGIE.x))

#colnames(data)[colnames(data) == "SECTOR.y"] <- "SECTOR"
#colnames(data)[colnames(data) == "PUBPRIVATE.y"] <- "PUBPRIVATE"
#colnames(data)[colnames(data) == "RELAFFIL.y"] <- "RELAFFIL"
#colnames(data)[colnames(data) == "DEGGRANT.y"] <- "DEGGRANT"
#colnames(data)[colnames(data) == "CARNEGIE.y"] <- "CARNEGIE"

#remove private for profit
#data <- data %>% filter(PUBPRIVATE != "Private for-profit")



data <- data %>% filter(SECTOR != "Private for-profit, 2-year" & SECTOR != "Private for-profit, 4-year or above" & SECTOR != "Private for-profit, less-than 2-year")

#remove adminsitrative units (no data)

data <- data %>% filter(SECTOR != "Administrative Unit")

#remove sector unknown (no data)
data <- data %>% filter(SECTOR != "Sector unknown (not active)")





#write.csv(data, "C:/Users/Sarah McDonald/Documents/honorsthesis/manipulated_data/ipeds-socio-geo.csv", row.names = FALSE)

```


Hispanic Population counts
https://seer.cancer.gov/popdata/singleages.html
https://seer.cancer.gov/popdata/popdic.html

```{r, warning= FALSE, message = FALSE}
his <- read.table("C:/Users/Sarah McDonald/Documents/honorsthesis/raw_data/hispanic_pop.txt")
#extracting needed variables
his$Year <- substr(his$V1, 1,4)
his$State<- substr(his$V1, 5,6)
his$FIPS<- substr(his$V1, 7,11)
his$Origin <- substr(his$V1, 15,15)
his$Population <-substr(his$V1, 19, 26)

#change population to numeric
his$Population <- as.numeric(his$Population)

#labeling for readability
his$Origin[his$Origin=="1"] <- "Hispanic"
his$Origin[his$Origin=="0"] <- "Non-Hispanic"

#counts of population for year, state, fips, origin, and hispanic/nonhispanic
his <- his %>% group_by(Year, FIPS, Origin) %>%
  summarize(Population= sum(Population))

#hispanic and nonhispanic columns
his <- his %>% spread(key = Origin, value = Population)

#total population
his$total_pop = his$Hispanic + his$`Non-Hispanic`

#percent hispanic
his$his_prop = (his$Hispanic/his$total_pop)


data <- merge(data, his[, c("Year", "FIPS", "his_prop")], by.x = c("YEAR", "GEOID"), by.y = c("Year", "FIPS"), all.x = TRUE)
```


annual personal income by county 1969-2017
https://www.bea.gov/data/income-saving/personal-income-county-metro-and-other-areas
```{r, warning= FALSE, message = FALSE}
income <- read.csv("C:/Users/Sarah McDonald/Documents/honorsthesis/raw_data/income_per_capita.csv")

income<- income[, -c(3:6, 8)]


#remove notes at last three observations
levels(income$Description)
income %>% filter(Description == "")
income[9595:9597,]

income <- income[-c(9595:9597),]


colnames(income) <- sub("X", "", colnames(income))

income <- income %>% 
  gather(`1969`, `1970`, `1971`, `1972`, `1973`, `1974`, `1975`, `1976`, `1977`, `1978`, `1979`, `1980`, `1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`, `1991`, `1992`, `1993`, `1994`, `1995`, `1996`, `1997`, `1998`, `1999`, `2000`, `2001`, `2002`, `2003`, `2004`, `2005`, `2006`, `2007`, `2008`, `2009`, `2010`, `2011`, `2012`, `2013`, `2014`, `2015`, `2016`, `2017`, key = "year", value = "amount")

income$Description <- as.character(as.factor(income$Description))

income$Description[income$Description=="Personal income (thousands of dollars)"] <- "personal_income"
income$Description[income$Description=="Population (persons) 1/"] <- "population"
income$Description[income$Description=="Per capita personal income (dollars) 2/"] <- "income_per_capita"

income <- income %>% spread(key = Description, value = amount)
income$year <- as.numeric(income$year)

income <- income[!(income$year < 1990),]
income$year <- as.character(income$year)
income <- income[!grepl("\\d\\d000", income$GeoFIPS),]
income <- income[, c(1,3,4)]
income$GeoFIPS <- as.character(as.factor(income$GeoFIPS))

income$GeoFIPS <- trimws(income$GeoFIPS, "left")

data <- merge(data, income, by.x= c("YEAR", "GEOID"), by.y = c("year", "GeoFIPS"), all.x = TRUE)
```




From 2017 Census shapefiles
```{r, warning=FALSE, message= FALSE}
counties
pop_dens <- counties %>% select(STATEFP, COUNTYFP, GEOID, ALAND)
pop_dens<-st_set_geometry(pop_dens, NULL)

pop_dens <- merge(x = pop_dens, y = his[, c("FIPS", "total_pop", "Year")], by.x = "GEOID", by.y = "FIPS", all.x = TRUE)

pop_dens$pop_dens <- pop_dens$total_pop/pop_dens$ALAND

pop_dens <- pop_dens[,c(1,6,7)]
pop_dens$GEOID <- as.character(as.factor(pop_dens$GEOID))

data <- merge(data, pop_dens, by.x = c("YEAR", "GEOID"), by.y = c("Year", "GEOID"), all.x = TRUE)
```

NEED CATHOLIC DATA



negative publicity data
```{r, warning=FALSE, message=FALSE}
url <- paste("http://origin.bishop-accountability.org/priestdb/PriestDBbylastName-", "A", ".html", sep="")
webpage <- read_html(url)

tbl <- webpage %>%
  html_nodes("table") %>%
  .[4] %>%
  html_table(fill = TRUE)

tbl <- as.data.frame((tbl))
names(tbl) = tbl[1, ] # the first row will be the header
tbl <- tbl[-1,]

for (i in 2:length(LETTERS)){
  i <- LETTERS[i]
  url <- paste("http://origin.bishop-accountability.org/priestdb/PriestDBbylastName-", i, ".html", sep="")
  webpage <- read_html(url)
  
  tbls <- html_nodes(webpage, "table")
  
  tbl_i <- webpage %>%
    html_nodes("table") %>%
    .[4] %>%
    html_table(fill = TRUE)
  
  tbl_i <- as.data.frame((tbl_i))
  
  names(tbl_i) = tbl_i[1, ] # the first row will be the header
  tbl <- rbind(tbl, tbl_i[-1,])
}

tbl <-tbl[!apply(tbl == "", 1, all),]


#hand classify these
tbl1 <- tbl %>% filter(str_detect(tbl$Notes, "died|retired"))

# code classify these
tbl2 <- tbl %>% filter(str_detect(tbl$Notes, "died|retired", negate = TRUE))

# Select source only
tbl2$Source = str_extract_all(tbl2$`Source/Assignments` , "(Source:.+)(?=Assignments)|(Source:.+$)")
# Find dates only
tbl2$Source <- str_extract_all(tbl2$Source, "\\d{1,}\\.\\d{1,}\\.\\d{1,}")

tbl2$public <- ""

for (i in 1: length(tbl2$Source)){
  y <- tbl2$Source[[i]]
  y <- str_extract_all(y, "\\d{1,2}$")
  y <- as.integer(y)
  y <- ifelse(y>22, y+1900, y+2000)
  y<- min(y)
  
  tbl2$public[i] <- y
}
tbl2$public <- as.numeric(tbl2$public)
tbl2 <- separate(tbl2, col = "Diocese", into = c("Diocese", "State"), sep = ",")

tbl2$ID <- as.character(seq.int(nrow(tbl2)))

duplicates <- tbl2 %>% filter(Diocese == "Springfield" | Diocese== "Portland" | Diocese == "Lafayette")

duplicates <- unite(duplicates,  Diocese, c(Diocese, State), sep = "", remove=FALSE)

tbl2 <- tbl2 %>% filter(Diocese !=  "Springfield" & Diocese != "Lafayette"& Diocese !="Portland")

tbl2 <- rbind(tbl2, duplicates)



bishop_pub <-tbl2 %>% group_by(Diocese, public) %>% tally()
colnames(bishop_pub)[colnames(bishop_pub)=="n"] <- "bishop_pub"

dioceses_bishop <- unique(bishop_pub$Diocese)
data <- read.csv("C:/Users/Sarah McDonald/Documents/honorsthesis/manipulated_data/ipeds-socio-geo.csv")

dioceses_data <- unique(data$Dioceses)
dioceses_data <- as.character(as.factor(dioceses_data))

subset(dioceses_bishop, !(dioceses_bishop %in% dioceses_data))
subset(dioceses_data, !(dioceses_data %in% dioceses_bishop))


bishop_pub$Diocese[bishop_pub$Diocese=="Fort Wayne-South Bend"] <- "Fort Wayne - South Bend"
bishop_pub$Diocese[bishop_pub$Diocese=="Kansas City"] <- "Kansas City KS"
bishop_pub$Diocese[bishop_pub$Diocese=="St. Paul-Minneapolis"] <- "St. Paul &amp; Minneapolis"
bishop_pub$Diocese[bishop_pub$Diocese=="Kansas City KS-St. Joseph"] <- "Kansas City-St. Joseph"

bishop_pub$Diocese[bishop_pub$Diocese=="Lafayette IN"] <- "Lafayette in Indiana"
bishop_pub$Diocese[bishop_pub$Diocese=="Lafayette LA"] <- "Lafayette in Louisiana"
bishop_pub$Diocese[bishop_pub$Diocese=="Portland ME"] <- "Portland in Maine"
bishop_pub$Diocese[bishop_pub$Diocese=="Portland OR"] <- "Portland in Oregon"
bishop_pub$Diocese[bishop_pub$Diocese=="Springfield MA"] <- "Springfield in Massachusetts"
bishop_pub$Diocese[bishop_pub$Diocese=="Springfield IL"] <- "Springfield in Illinois"






dioceses_bishop <- gsub("Fort Wayne-South Bend", "Fort Wayne - South Bend", dioceses_bishop)
dioceses_bishop <- gsub("Kansas City", "Kansas City KS", dioceses_bishop)
dioceses_bishop<- gsub("St. Paul-Minneapolis", "St. Paul &amp; Minneapolis", dioceses_bishop)
dioceses_bishop<- gsub("Kansas City KS-St. Joseph", "Kansas City-St. Joseph", dioceses_bishop)


dioceses_bishop<- gsub("Lafayette IN", "Lafayette in Indiana", dioceses_bishop)
dioceses_bishop<- gsub("Lafayette LA", "Lafayette in Louisiana", dioceses_bishop)
dioceses_bishop<- gsub("Portland ME", "Portland in Maine", dioceses_bishop)
dioceses_bishop<- gsub("Portland OR", "Portland in Oregon", dioceses_bishop)
dioceses_bishop<- gsub("Springfield MA", "Springfield in Massachusetts", dioceses_bishop)
dioceses_bishop<- gsub("Springfield IL", "Springfield in Illinois", dioceses_bishop)

#data does not classify DC Schools Dioceses
#will need to specify springfield (IL or MA), Lafayette (IN, Lousiana), Portland (OR, MAINE)


```




DC Schools
https://opendata.dc.gov/datasets/7241f6d500b44288ad983f0942b39663_10/data
```{r}

dc <- st_read("C:/Users/Sarah McDonald/Documents/honorsthesis/KML/Washington_DC_Boundary.kml")
dc = st_transform(dc, st_crs(cath_geo))

dataNA <- data %>% filter(is.na(Dioceses) == TRUE)
coords_NA <- dataNA %>% filter(YEAR == 2017 & LINE == "Total") %>% select(UNITID, LONGITUD, LATITUDE)

coords_NA = st_as_sf(coords_NA, coords = c("LONGITUD", "LATITUDE"), crs = st_crs(cath_geo))


dcUNITIDs <- st_join(dc, coords_NA)

dcIDs <- dcUNITIDs$UNITID


levels(data$Dioceses) <- c(levels(data$Dioceses),"Washington DC")

data$Dioceses[data$UNITID %in% dcIDs] <- "Washington DC"

dataNA <- data %>% filter(is.na(Dioceses) == TRUE) #many of the NAs are technical schools

data$Dioceses[data$INSTNM %like% "HAWAII"] <- "Honolulu"

dataNA <- data %>% filter(is.na(Dioceses) == TRUE) #many of the NAs are technical schools

#filter out american samoa
data<-data %>% filter(!(INSTNM %like% "SAMOA"))

data<-data %>% filter(!(INSTNM %like% "PUERTO RICO"))

data<-data %>% filter(!(INSTNM %like% "GUAM"))

data<-data %>% filter(!(INSTNM %like% "MARSHALL ISLANDS"))

#I can connect universities straight to dioceses without going through counties

na <- st_join(cath_geo, coords_NA)

other <- st_join(cath_geo, coords_17)

```

https://www.huduser.gov/portal/datasets/usps_crosswalk.html zip code to county cross walk




ADD NEGATIVE PUBLICITY


